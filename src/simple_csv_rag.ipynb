{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:10.083464Z",
     "start_time": "2026-02-20T21:54:09.399477Z"
    }
   },
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T22:48:32.625460Z",
     "start_time": "2026-02-20T22:48:22.068020Z"
    }
   },
   "source": [
    "file_path = \"data/requetes311.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#preview the csv file\n",
    "data"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y2/bxbn9j2n1nn68rb5sxx6lvhr0000gn/T/ipykernel_37713/2644414103.py:2: DtypeWarning: Columns (0: ID_UNIQUE, 1: TYPE_LIEU_INTERV, 2: RUE, 3: RUE_INTERSECTION1, 4: RUE_INTERSECTION2, 5: ARRONDISSEMENT, 6: ARRONDISSEMENT_GEO, 7: LIN_CODE_POSTAL, 8: DERNIER_STATUT) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID_UNIQUE                  343029\n",
      "NATURE                     639090\n",
      "ACTI_NOM                   639090\n",
      "TYPE_LIEU_INTERV           343029\n",
      "RUE                        296022\n",
      "RUE_INTERSECTION1           51866\n",
      "RUE_INTERSECTION2           51830\n",
      "LOC_ERREUR_GDT             342800\n",
      "ARRONDISSEMENT             343029\n",
      "ARRONDISSEMENT_GEO         342786\n",
      "LIN_CODE_POSTAL            268534\n",
      "DDS_DATE_CREATION          639090\n",
      "PROVENANCE_ORIGINALE       638675\n",
      "PROVENANCE_TELEPHONE       639090\n",
      "PROVENANCE_COURRIEL        639090\n",
      "PROVENANCE_PERSONNE        639090\n",
      "PROVENANCE_COURRIER        639090\n",
      "PROVENANCE_TELECOPIEUR     639090\n",
      "PROVENANCE_INSTANCE        639090\n",
      "PROVENANCE_MOBILE          639090\n",
      "PROVENANCE_MEDIASOCIAUX    639090\n",
      "PROVENANCE_SITEINTERNET    639090\n",
      "UNITE_RESP_PARENT          639090\n",
      "LOC_LONG                   342800\n",
      "LOC_LAT                    342800\n",
      "LOC_X                      342800\n",
      "LOC_Y                      342800\n",
      "DERNIER_STATUT             343029\n",
      "DATE_DERNIER_STATUT        639090\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:18.475879Z",
     "start_time": "2026-02-20T21:54:18.474367Z"
    }
   },
   "source": [
    "#loader = CSVLoader(file_path=file_path)\n",
    "#docs = loader.load_and_split()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:23.548161Z",
     "start_time": "2026-02-20T21:54:18.555838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def create_metadata_chunks(df):\n",
    "    metadata_docs = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # On récupère les valeurs uniques (limitées pour ne pas exploser le prompt)\n",
    "        unique_values = df[col].unique()[:50].tolist() \n",
    "        count_unique = df[col].nunique()\n",
    "        \n",
    "        content = (\n",
    "            f\"Colonne: {col}\\n\"\n",
    "            f\"Nombre de valeurs uniques: {count_unique}\\n\"\n",
    "            f\"Exemples de valeurs: {', '.join(map(str, unique_values))}\"\n",
    "        )\n",
    "        \n",
    "        metadata_docs.append(Document(\n",
    "            page_content=content, \n",
    "            metadata={\"type\": \"schema\", \"column\": col}\n",
    "        ))\n",
    "    return metadata_docs\n",
    "\n",
    "docs = create_metadata_chunks(data)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:23.995997Z",
     "start_time": "2026-02-20T21:54:23.553428Z"
    }
   },
   "source": [
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "import faiss\n",
    "\n",
    "# 1. Initialiser les embeddings Ollama\n",
    "# Assurez-vous d'avoir fait : ollama pull nomic-embed-text\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# 2. Déterminer la dimension de l'index automatiquement\n",
    "\n",
    "sample_embedding = embeddings.embed_query(\"test\")\n",
    "dimension = len(sample_embedding)\n",
    "\n",
    "# 3. Créer l'index FAISS\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:25.407200Z",
     "start_time": "2026-02-20T21:54:24.014559Z"
    }
   },
   "source": [
    "vector_store.add_documents(documents=docs)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['7e2eb41d-5dc1-45dd-a9be-06c4a7539cc4',\n",
       " '704040c9-d1ac-415f-8475-e9cf50a91688',\n",
       " '1e1bfff0-226c-43fa-be47-03d58c6abe3c',\n",
       " '8c130957-692c-4db3-9d78-26e165581d3e',\n",
       " 'f721df29-1cb6-4b8d-8f11-37d8d5baa23a',\n",
       " 'a2c1157f-2aff-4f68-bcda-96fbc8fc95e8',\n",
       " '0721f79b-9c42-4130-bee0-2f7d8806286d',\n",
       " '30616111-2dcc-4524-8edb-4546f3ddb9f2',\n",
       " '93fc7f4b-6fd5-46b1-9e82-36adca360acd',\n",
       " '8854e323-6a91-4f79-b0f4-487a7026a0d4',\n",
       " '6ee22a92-e7d2-440b-9d49-c338c35fec94',\n",
       " '35242b48-6059-45d6-b380-d2bd8e297f1e',\n",
       " 'ab4410f1-1683-4ba6-9ad9-67c6fe2e2b7a',\n",
       " 'e0d5d664-2edf-4cc5-a5b4-9a8cb0adf9d5',\n",
       " '1c53eb2b-ca36-4aaf-b73c-4b704cfb9f6d',\n",
       " '813740d6-b3cc-4ee0-9c69-366b003bc39c',\n",
       " '894d967a-ffda-4628-bc3c-ac41ac6e945d',\n",
       " 'c3175c28-0cc8-41e9-b0a9-699123c7bf8f',\n",
       " 'dbfaab78-a415-4d81-84bc-fcc10b0c9099',\n",
       " '011ce585-f47e-487e-a885-450a27a6512b',\n",
       " 'db690efc-38df-4c8b-a5ea-0dad4409e5c8',\n",
       " '4d75e31d-4a7f-4143-a250-eff8cd65515a',\n",
       " '1a586e9a-ba34-4979-b75b-e4ba7ac7ff13',\n",
       " 'fb56dc25-d606-4d94-a221-fbeee296469c',\n",
       " '8526db8e-90c8-4829-bc09-967ef433b4dd',\n",
       " 'b09c2bf5-d0dd-4cfb-bab0-2d97a91de8ec',\n",
       " 'e5aee98d-912b-455c-853a-66d7af4b256e',\n",
       " '2a4b7f04-a056-46dc-a1c1-ba10ea39cd88',\n",
       " 'dd289973-945e-4b99-9b79-1e2523df99b8']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:54:25.560699Z",
     "start_time": "2026-02-20T21:54:25.423323Z"
    }
   },
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "# 1. Initialiser le modèle LLM local via Ollama\n",
    "# Vous pouvez changer \"llama3\" par \"mistral\" ou tout autre modèle téléchargé\n",
    "llm = ChatOllama(model=\"gemma3:4b\")\n",
    "\n",
    "# 2. Configurer le retriever à partir de votre vector_store FAISS précédent\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# 3. Définir le prompt système\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# 4. Créer la chaîne de documents (RAG)\n",
    "# On passe ici le LLM Ollama défini plus haut\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# --- Exemple d'utilisation ---\n",
    "# response = rag_chain.invoke({\"input\": \"Quelle est la question ?\"})\n",
    "# print(response[\"answer\"])"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-20T21:58:40.285271Z",
     "start_time": "2026-02-20T21:58:30.906300Z"
    }
   },
   "source": [
    "answer= rag_chain.invoke({\"input\": \"Quels sont les appels les plus courants ?\"})\n",
    "answer['answer']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Je ne peux pas répondre à cette question avec les informations fournies. Les données fournies listent uniquement les noms des colonnes et le nombre de valeurs uniques dans chaque colonne, ainsi que quelques exemples de valeurs.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--simple-csv-rag)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
